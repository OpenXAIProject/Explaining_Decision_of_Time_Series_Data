{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import nn_ops, gen_nn_ops\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_MC_dropout:\n",
    "    def __init__(self, std=0.01 , batch_size=64,width=500, height =1, input_channel=3, l_rate =1e-6,reuse = False):\n",
    "        self.std=std\n",
    "        self.batch_size=batch_size\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.input_channel = input_channel\n",
    "        self.l_rate = l_rate\n",
    "\n",
    "        with tf.name_scope('Classifier'):\n",
    "            self.y = tf.placeholder(tf.float32, [None, 3], name='y')\n",
    "            self.x = tf.placeholder(tf.float32, [None, self.height,self.width,self.input_channel], name='x')\n",
    "            self.dropout_bool = tf.placeholder(tf.bool, [None,1])\n",
    "            self.keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "        self.logits = self.build_model()\n",
    "\n",
    "        # Define loss and optimizer, minimize the squared error\n",
    "        self.cross_entropy = cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.y, logits=self.logits)\n",
    "        self.cost =tf.reduce_mean(self.cross_entropy)\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.l_rate).minimize(self.cost)\n",
    "\n",
    "        self.correct_pred = tf.equal(tf.round(self.prediction),self.y)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Launch the session\n",
    "        self.session_conf = tf.ConfigProto()\n",
    "        self.session_conf.gpu_options.allow_growth = True\n",
    "        self.sess = tf.InteractiveSession(config=self.session_conf)\n",
    "        self.sess.run(init)\n",
    "\n",
    "        self.saver = tf.train.Saver(max_to_keep=None)\n",
    "\n",
    "    def build_model(self):\n",
    "        with tf.variable_scope('layer0'):\n",
    "            #b, h, w, c\n",
    "            self.input = self.x\n",
    "        # Convolutional Layer #1 and Pooling Layer #1\n",
    "        with tf.variable_scope('layer1'):\n",
    "            self.conv1 = tf.layers.conv2d(self.input, 128, [8,1], padding='SAME')\n",
    "            self.batch1 = tf.layers.batch_normalization(self.conv1)\n",
    "            self.relu1 = tf.nn.relu(self.batch1)\n",
    "            self.dropout1 = tf.layers.dropout(self.relu1, self.keep_prob,self.dropout_bool)\n",
    "\n",
    "        # Convolutional Layer #1 and Pooling Layer #2\n",
    "        with tf.variable_scope('layer2'):\n",
    "            self.conv2 = tf.layers.conv2d(self.dropout1, 256, [5,1], padding='SAME')\n",
    "            self.batch2 = tf.layers.batch_normalization(self.conv2)\n",
    "            self.relu2 = tf.nn.relu(self.batch2)\n",
    "            self.dropout2 = tf.layers.dropout(self.relu2, self.keep_prob,self.dropout_bool)\n",
    "\n",
    "        # Convolutional Layer #1 and Pooling Layer #3\n",
    "        with tf.variable_scope('layer3'):\n",
    "            self.conv3 = tf.layers.conv2d(self.dropout2, 128, [3,1], padding='SAME')\n",
    "            self.batch3 = tf.layers.batch_normalization(self.conv3)\n",
    "            self.relu3 = tf.nn.relu(self.batch3)\n",
    "\n",
    "        # Dense Layer with Relu\n",
    "        with tf.variable_scope('layer4'):\n",
    "            #Global Average Pooling\n",
    "            self.GAP = tf.reduce_mean(self.relu3, axis=[1,2])# b,h,w,c\n",
    "            self.logits = tf.layers.dense(self.GAP,3)\n",
    "            self.prediction = tf.nn.softmax(self.logits)\n",
    "            \n",
    "        return self.logits\n",
    "\n",
    "\n",
    "    def train(self, data, target, keep_prob,dropout_bool):\n",
    "        opt, cost ,acc = self.sess.run((self.optimizer, self.cost, self.accuracy ), \n",
    "                             feed_dict={self.y: target,\n",
    "                                        self.x: data,\n",
    "                                       self.keep_prob: keep_prob,\n",
    "                                       self.dropout_bool : dropout_bool})\n",
    "        return cost,acc\n",
    "\n",
    "    def test(self, data, target, keep_prob,dropout_bool):\n",
    "        cost,acc = self.sess.run((self.cost,self.accuracy),\n",
    "                             feed_dict={self.y: target,\n",
    "                                        self.x: data,\n",
    "                                       self.keep_prob: keep_prob,\n",
    "                                       self.dropout_bool : dropout_bool})\n",
    "        return cost,acc\n",
    "\n",
    "    def get_last_conv_output(self, data, keep_prob):\n",
    "        relu3 =  self.sess.run((self.relu3), \n",
    "                             feed_dict={self.x: data,\n",
    "                                       self.keep_prob: keep_prob})\n",
    "        return relu3\n",
    "    \n",
    "\n",
    "    def save(self, save_path='./model.ckpt'):\n",
    "        saved_path = self.saver.save(self.sess, save_path)\n",
    "        print(\"Model saved in file: %s\"%saved_path)\n",
    "\n",
    "    def load(self, load_path = './model.ckpt'):\n",
    "        self.saver.restore(self.sess, load_path)\n",
    "        print(\"Model restored\")\n",
    "\n",
    "    def terminate(self):\n",
    "        self.sess.close()\n",
    "        tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Load\n",
    "### 전처리 width, height, input_channel 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataload~\n",
    "Y = dataload~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예시\n",
    "width = X.shape[0]\n",
    "height = X.shape[1]\n",
    "input_channel = X.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training condition 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_loss=[]\n",
    "t_acc=[]\n",
    "\n",
    "v_loss=[]\n",
    "v_acc=[]\n",
    "\n",
    "val_freq = 1\n",
    "save_freq = 1\n",
    "num_epochs= 50\n",
    "\n",
    "\n",
    "std= 0.01\n",
    "batch_size =128\n",
    "l_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = pd.DataFrame(index=np.arange(0, num_epochs), columns=['epoch', 'loss', 'acc','timestamp'])\n",
    "valid_history = pd.DataFrame(index=np.arange(0, num_epochs/val_freq),columns=['epoch', 'loss', 'acc','timestamp'])\n",
    "hot_encoded_target = np.asarray(pd.get_dummies(np.asarray(Y).flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. model structure 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'MC_dropout_model' in globals():\n",
    "    MC_dropout_model.terminate()\n",
    "    \n",
    "    \n",
    "MC_dropout_model =CNN_MC_dropout(width= width, height=height,input_channel=input_channel ,std=std,batch_size=batch_size,l_rate=l_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (MC_dropout_model.input)\n",
    "print ('[layer1] - MC dropout')\n",
    "print (MC_dropout_model.conv1)\n",
    "print (MC_dropout_model.batch1)\n",
    "print (MC_dropout_model.relu1)\n",
    "print (MC_dropout_model.dropout1)\n",
    "print ('[layer2] - MC dropout')\n",
    "print (MC_dropout_model.conv2)\n",
    "print (MC_dropout_model.batch2)\n",
    "print (MC_dropout_model.relu2)\n",
    "print (MC_dropout_model.dropout2)\n",
    "print ('[layer3]')\n",
    "print (MC_dropout_model.conv3)\n",
    "print (MC_dropout_model.batch3)\n",
    "print (MC_dropout_model.relu3)\n",
    "\n",
    "print ('[layer4]')\n",
    "print (MC_dropout_model.GAP)\n",
    "print (MC_dropout_model.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout을 training시에는 적용시키지 않고, prediction 시에만 적용\n",
    "#따라서 train에서는 keep prob = 1.0, dropout_bool = False\n",
    "\n",
    "for epoch in range(0,epoch):\n",
    "    for batch in getbatch(X,Y):\n",
    "        train_in , train_target = batch[0],batch[1]\n",
    "        MC_dropout_model.train(data=train_in,target= train_target, keep_prob=1.0, dropout_bool=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Trained 된 모델에서 Last Conv output Load하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction 시에는 MC dropout 을 적용\n",
    "# keep_prob = 0.5(survive 확률) , dropout_bool=True\n",
    "\n",
    "#각 데이터 마다 MC dropout 을 B 번 적용한다면, B 개의 서로 다른 model structure를 거치며 나타난 last conv output을 각 노드마다 모두 저장해놓음\n",
    "\n",
    "#예를들어, unit 1이 보는 pattern을 모두 last_conv_patter1에 저장\n",
    "#데이터가 N 개이고, MC dropout 횟수가 B번이라면, 총 N*B개의 패턴이 저장됨\n",
    "last_conv_pattern1=[]\n",
    "B = MCdropout횟수\n",
    "\n",
    "for batch in getbatch(X,Y):\n",
    "    for i in range(0,B):\n",
    "        output = MC_dropout_model.get_last_conv_output(data=train_in,target= train_target,keep_prob=0.5,dropout_bool=True)\n",
    "        pattern = output[output>threshold]\n",
    "        last_conv_pattern1.append(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. pattern 저장해 놓은 것을 clustering 해서 라벨 붙혀주기?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 각 노드당 pattern의 entropy 계산하여 uncertainty 계산?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. uncertainty 가 특정 threshold보다 낮을 경우, pattern과 unit 매칭"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
